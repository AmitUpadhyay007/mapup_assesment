{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3cfb469",
   "metadata": {},
   "source": [
    "### Python Section 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f584b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001e5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daba53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_by_n_elements(lst: List[int], n: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Reverses the input list by groups of n elements.\n",
    "    \"\"\"\n",
    "     # Traverse the list in chunks of size 'n'\n",
    "    for i in range(0, len(lst), n):\n",
    "        # Determine the end index for the current group\n",
    "        end = min(i + n, len(lst))\n",
    "        \n",
    "        # Manually reverse the group by swapping elements\n",
    "        left = i\n",
    "        right = end - 1\n",
    "        while left < right:\n",
    "            lst[left], lst[right] = lst[right], lst[left]\n",
    "            left += 1\n",
    "            right -= 1\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04141b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 6, 5, 4, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "print(reverse_by_n_elements([1, 2, 3, 4, 5, 6, 7, 8], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f6e6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_length(lst: List[str]) -> Dict[int, List[str]]:\n",
    "    \"\"\"\n",
    "    Groups the strings by their length and returns a dictionary.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to hold the groups\n",
    "    length_dict = {}\n",
    "    \n",
    "    # Loop through each string in the list\n",
    "    for s in lst:\n",
    "        length = len(s)\n",
    "        \n",
    "        # Add the string to the corresponding list in the dictionary\n",
    "        if length not in length_dict:\n",
    "            length_dict[length] = []\n",
    "        length_dict[length].append(s)\n",
    "    \n",
    "    # Return the dictionary sorted by keys (lengths)\n",
    "    return dict(sorted(length_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "463fe84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['bat', 'car', 'dog'], 4: ['bear'], 5: ['apple'], 8: ['elephant']}\n"
     ]
    }
   ],
   "source": [
    "print(group_by_length([\"apple\", \"bat\", \"car\", \"elephant\", \"dog\", \"bear\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1fb275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['one', 'two'], 4: ['four'], 5: ['three']}\n"
     ]
    }
   ],
   "source": [
    "print(group_by_length([\"one\", \"two\", \"three\", \"four\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4d28448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(nested_dict: Dict, sep: str = '.') -> Dict:\n",
    " def _flatten(current_dict, parent_key=''):\n",
    "        items = []\n",
    "        for k, v in current_dict.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k  # Create the new key\n",
    "            if isinstance(v, dict):  # If value is a dict, recurse\n",
    "                items.extend(_flatten(v, new_key).items())\n",
    "            elif isinstance(v, list):  # If value is a list, flatten by index\n",
    "                for i, item in enumerate(v):\n",
    "                    list_key = f\"{new_key}[{i}]\"\n",
    "                    if isinstance(item, dict):\n",
    "                        items.extend(_flatten(item, list_key).items())\n",
    "                    else:\n",
    "                        items.append((list_key, item))\n",
    "            else:  # If it's neither dict nor list, just append it\n",
    "                items.append((new_key, v))\n",
    "        return dict(items)\n",
    " return _flatten(nested_dict)\n",
    "\n",
    "nested_dict = {\n",
    "    \"road\": {\n",
    "        \"name\": \"Highway 1\",\n",
    "        \"length\": 350,\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"condition\": {\n",
    "                    \"pavement\": \"good\",\n",
    "                    \"traffic\": \"moderate\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a82ac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'road.name': 'Highway 1', 'road.length': 350, 'road.sections[0].id': 1, 'road.sections[0].condition.pavement': 'good', 'road.sections[0].condition.traffic': 'moderate'}\n"
     ]
    }
   ],
   "source": [
    "print(flatten_dict(nested_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4db2407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 2], [1, 2, 1], [2, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "def unique_permutations(nums: List[int]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Generates all unique permutations of the given list of integers.\n",
    "    \n",
    "    :param nums: A list of integers that may contain duplicates\n",
    "    :return: A list of unique permutations\n",
    "    \"\"\"\n",
    "    def backtrack(path, used):\n",
    "        # If the current path is a complete permutation, add it to the result\n",
    "        if len(path) == len(nums):\n",
    "            result.append(path[:])\n",
    "            return\n",
    "        \n",
    "        for i in range(len(nums)):\n",
    "            # Skip used elements or duplicate elements to avoid redundant work\n",
    "            if used[i] or (i > 0 and nums[i] == nums[i - 1] and not used[i - 1]):\n",
    "                continue\n",
    "            \n",
    "            # Mark the element as used and recurse\n",
    "            used[i] = True\n",
    "            path.append(nums[i])\n",
    "            backtrack(path, used)\n",
    "            # Backtrack: Unmark the element and remove it from the path\n",
    "            used[i] = False\n",
    "            path.pop()\n",
    "    \n",
    "    nums.sort()  # Sort the list to handle duplicates\n",
    "    result = []\n",
    "    used = [False] * len(nums)  # Track used elements\n",
    "    backtrack([], used)\n",
    "    return result\n",
    "\n",
    "# Test case\n",
    "print(unique_permutations([1, 1, 2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd174e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23-08-1994', '08/23/1994', '1994.08.23']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_all_dates(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function takes a string as input and returns a list of valid dates\n",
    "    in 'dd-mm-yyyy', 'mm/dd/yyyy', or 'yyyy.mm.dd' format found in the string.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): A string containing the dates in various formats.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of valid dates in the formats specified.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern for matching dates in the specified formats\n",
    "    date_pattern = r\"\\b\\d{2}-\\d{2}-\\d{4}\\b|\\b\\d{2}/\\d{2}/\\d{4}\\b|\\b\\d{4}\\.\\d{2}\\.\\d{2}\\b\"\n",
    "    \n",
    "    # Find all matches using the regular expression\n",
    "    matches = re.findall(date_pattern, text)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Test case\n",
    "text = \"I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23.\"\n",
    "print(find_all_dates(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05611197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude  longitude       distance\n",
      "0  41.86639   -120.200       0.000000\n",
      "1  44.06639   -120.950  252122.397509\n",
      "2  46.61839   -126.453  515078.047668\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polyline\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from typing import List, Tuple\n",
    "\n",
    "def haversine(coord1: Tuple[float, float], coord2: Tuple[float, float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two (latitude, longitude) coordinates.\n",
    "    \n",
    "    Args:\n",
    "        coord1 (tuple): A tuple representing the first point (latitude, longitude).\n",
    "        coord2 (tuple): A tuple representing the second point (latitude, longitude).\n",
    "    \n",
    "    Returns:\n",
    "        float: The distance between the two points in meters.\n",
    "    \"\"\"\n",
    "    R = 6371000  # Radius of Earth in meters\n",
    "    lat1, lon1 = radians(coord1[0]), radians(coord1[1])\n",
    "    lat2, lon2 = radians(coord2[0]), radians(coord2[1])\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a polyline string into a DataFrame with latitude, longitude, and distance between consecutive points.\n",
    "    \n",
    "    Args:\n",
    "        polyline_str (str): The encoded polyline string.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing latitude, longitude, and distance in meters.\n",
    "    \"\"\"\n",
    "    # Decode the polyline string to a list of (latitude, longitude) coordinates\n",
    "    coordinates = polyline.decode(polyline_str)\n",
    "    \n",
    "    # Create a DataFrame from the coordinates\n",
    "    df = pd.DataFrame(coordinates, columns=['latitude', 'longitude'])\n",
    "    \n",
    "    # Initialize the distance column\n",
    "    distances = [0]  # First row has 0 distance\n",
    "    \n",
    "    # Calculate the distance between successive rows using the Haversine formula\n",
    "    for i in range(1, len(coordinates)):\n",
    "        coord1 = coordinates[i - 1]\n",
    "        coord2 = coordinates[i]\n",
    "        distance = haversine(coord1, coord2)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    # Add the distance column to the DataFrame\n",
    "    df['distance'] = distances\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Test case\n",
    "polyline_str = \"}_p~F~ps|U_ulLnnqC_mqNvxq`@\"\n",
    "df = polyline_to_dataframe(polyline_str)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0789e5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polylineNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading polyline-2.0.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Downloading polyline-2.0.2-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: polyline\n",
      "Successfully installed polyline-2.0.2\n"
     ]
    }
   ],
   "source": [
    "pip install polyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f0c061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29, 23, 17], [31, 25, 19], [33, 27, 21]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def rotate_and_multiply_matrix(matrix: List[List[int]]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Rotate the given matrix by 90 degrees clockwise, then replace each element \n",
    "    by the sum of all elements in the same row and column (excluding itself).\n",
    "    \n",
    "    Args:\n",
    "    - matrix (List[List[int]]): 2D list representing the matrix to be transformed.\n",
    "    \n",
    "    Returns:\n",
    "    - List[List[int]]: A new 2D list representing the transformed matrix.\n",
    "    \"\"\"\n",
    "    n = len(matrix)\n",
    "    \n",
    "    # Step 1: Rotate the matrix by 90 degrees clockwise\n",
    "    rotated_matrix = [[0] * n for _ in range(n)]  # Initialize the rotated matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            rotated_matrix[j][n - 1 - i] = matrix[i][j]\n",
    "    \n",
    "    # Step 2: Replace each element with the sum of its row and column (excluding itself)\n",
    "    final_matrix = [[0] * n for _ in range(n)]  # Initialize the final matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            row_sum = sum(rotated_matrix[i])  # Sum of the current row\n",
    "            col_sum = sum(rotated_matrix[k][j] for k in range(n))  # Sum of the current column\n",
    "            final_matrix[i][j] = row_sum + col_sum - rotated_matrix[i][j]  # Subtract the element itself\n",
    "    \n",
    "    return final_matrix\n",
    "\n",
    "# Test case\n",
    "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "result = rotate_and_multiply_matrix(matrix)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d676f401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>id_2</th>\n",
       "      <th>startDay</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endDay</th>\n",
       "      <th>endTime</th>\n",
       "      <th>able2Hov2</th>\n",
       "      <th>able2Hov3</th>\n",
       "      <th>able3Hov2</th>\n",
       "      <th>able3Hov3</th>\n",
       "      <th>able5Hov2</th>\n",
       "      <th>able5Hov3</th>\n",
       "      <th>able4Hov2</th>\n",
       "      <th>able4Hov3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1040000</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>-1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040010</td>\n",
       "      <td>Black</td>\n",
       "      <td>-1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>Friday</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1040020</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>-1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>Friday</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1040030</td>\n",
       "      <td>Foley</td>\n",
       "      <td>-1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Friday</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1050000</td>\n",
       "      <td>Whittier</td>\n",
       "      <td>1050001</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        name     id_2  startDay startTime     endDay   endTime  \\\n",
       "0  1040000  Montgomery       -1    Monday  05:00:00  Wednesday  10:00:00   \n",
       "1  1040010       Black       -1    Monday  10:00:00     Friday  15:00:00   \n",
       "2  1040020     Emerald       -1  Thursday  15:00:00     Friday  19:00:00   \n",
       "3  1040030       Foley       -1    Monday  19:00:00     Friday  23:59:59   \n",
       "4  1050000    Whittier  1050001  Saturday  00:00:00     Sunday  23:59:59   \n",
       "\n",
       "   able2Hov2  able2Hov3  able3Hov2  able3Hov3  able5Hov2  able5Hov3  \\\n",
       "0        3.0        3.0       -1.0         -1          3          3   \n",
       "1        6.0        6.0       -1.0         -1          6          6   \n",
       "2        3.0        3.0       -1.0         -1          3          3   \n",
       "3        6.0        6.0       -1.0         -1          6          6   \n",
       "4        6.0        6.0        NaN         -1          6          6   \n",
       "\n",
       "   able4Hov2  able4Hov3  \n",
       "0          3          3  \n",
       "1          6          6  \n",
       "2          3          3  \n",
       "3          6          6  \n",
       "4          6          6  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=\"E:/dataset-1.csv\", \n",
    "                              sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0367246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ï»¿id        name     id_2  startDay startTime     endDay   endTime  \\\n",
      "0  1040000  Montgomery       -1    Monday  05:00:00  Wednesday  10:00:00   \n",
      "1  1040010       Black       -1    Monday  10:00:00     Friday  15:00:00   \n",
      "2  1040020     Emerald       -1  Thursday  15:00:00     Friday  19:00:00   \n",
      "3  1040030       Foley       -1    Monday  19:00:00     Friday  23:59:59   \n",
      "4  1050000    Whittier  1050001  Saturday  00:00:00     Sunday  23:59:59   \n",
      "\n",
      "   able2Hov2  able2Hov3  able3Hov2  able3Hov3  able5Hov2  able5Hov3  \\\n",
      "0        3.0        3.0       -1.0         -1          3          3   \n",
      "1        6.0        6.0       -1.0         -1          6          6   \n",
      "2        3.0        3.0       -1.0         -1          3          3   \n",
      "3        6.0        6.0       -1.0         -1          6          6   \n",
      "4        6.0        6.0        NaN         -1          6          6   \n",
      "\n",
      "   able4Hov2  able4Hov3  \n",
      "0          3          3  \n",
      "1          6          6  \n",
      "2          3          3  \n",
      "3          6          6  \n",
      "4          6          6  \n",
      "Invalid startDay entries:\n",
      "         ï»¿id        name     id_2 startDay startTime endDay   endTime  \\\n",
      "0      1040000  Montgomery       -1      NaT  05:00:00    NaT  10:00:00   \n",
      "1      1040010       Black       -1      NaT  10:00:00    NaT  15:00:00   \n",
      "2      1040020     Emerald       -1      NaT  15:00:00    NaT  19:00:00   \n",
      "3      1040030       Foley       -1      NaT  19:00:00    NaT  23:59:59   \n",
      "4      1050000    Whittier  1050001      NaT  00:00:00    NaT  23:59:59   \n",
      "...        ...         ...      ...      ...       ...    ...       ...   \n",
      "39509  1031012     Baldwin  1031030      NaT  19:00:00    NaT  23:59:59   \n",
      "39510  1031012     Baldwin  1031032      NaT  00:00:00    NaT  23:59:59   \n",
      "39511  1031014    Thickson  1031016      NaT  00:00:00    NaT  23:59:59   \n",
      "39512  1031014    Thickson  1031018      NaT  05:00:00    NaT  10:00:00   \n",
      "39513  1031014    Thickson  1031020      NaT  10:00:00    NaT  15:00:00   \n",
      "\n",
      "       able2Hov2  able2Hov3  able3Hov2  able3Hov3  able5Hov2  able5Hov3  \\\n",
      "0            3.0        3.0       -1.0         -1          3          3   \n",
      "1            6.0        6.0       -1.0         -1          6          6   \n",
      "2            3.0        3.0       -1.0         -1          3          3   \n",
      "3            6.0        6.0       -1.0         -1          6          6   \n",
      "4            6.0        6.0        NaN         -1          6          6   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "39509       11.0       11.0        4.0          4         11         11   \n",
      "39510       11.0       11.0        4.0          4         11         11   \n",
      "39511       11.0       11.0        4.0          4         11         11   \n",
      "39512        8.0        8.0        4.0          4          8          8   \n",
      "39513       11.0       11.0        4.0          4         11         11   \n",
      "\n",
      "       able4Hov2  able4Hov3  \n",
      "0              3          3  \n",
      "1              6          6  \n",
      "2              3          3  \n",
      "3              6          6  \n",
      "4              6          6  \n",
      "...          ...        ...  \n",
      "39509         11         11  \n",
      "39510         11         11  \n",
      "39511         11         11  \n",
      "39512          8          8  \n",
      "39513         11         11  \n",
      "\n",
      "[39514 rows x 15 columns]\n",
      "Invalid endDay entries:\n",
      "         ï»¿id        name     id_2 startDay startTime endDay   endTime  \\\n",
      "0      1040000  Montgomery       -1      NaT  05:00:00    NaT  10:00:00   \n",
      "1      1040010       Black       -1      NaT  10:00:00    NaT  15:00:00   \n",
      "2      1040020     Emerald       -1      NaT  15:00:00    NaT  19:00:00   \n",
      "3      1040030       Foley       -1      NaT  19:00:00    NaT  23:59:59   \n",
      "4      1050000    Whittier  1050001      NaT  00:00:00    NaT  23:59:59   \n",
      "...        ...         ...      ...      ...       ...    ...       ...   \n",
      "39509  1031012     Baldwin  1031030      NaT  19:00:00    NaT  23:59:59   \n",
      "39510  1031012     Baldwin  1031032      NaT  00:00:00    NaT  23:59:59   \n",
      "39511  1031014    Thickson  1031016      NaT  00:00:00    NaT  23:59:59   \n",
      "39512  1031014    Thickson  1031018      NaT  05:00:00    NaT  10:00:00   \n",
      "39513  1031014    Thickson  1031020      NaT  10:00:00    NaT  15:00:00   \n",
      "\n",
      "       able2Hov2  able2Hov3  able3Hov2  able3Hov3  able5Hov2  able5Hov3  \\\n",
      "0            3.0        3.0       -1.0         -1          3          3   \n",
      "1            6.0        6.0       -1.0         -1          6          6   \n",
      "2            3.0        3.0       -1.0         -1          3          3   \n",
      "3            6.0        6.0       -1.0         -1          6          6   \n",
      "4            6.0        6.0        NaN         -1          6          6   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "39509       11.0       11.0        4.0          4         11         11   \n",
      "39510       11.0       11.0        4.0          4         11         11   \n",
      "39511       11.0       11.0        4.0          4         11         11   \n",
      "39512        8.0        8.0        4.0          4          8          8   \n",
      "39513       11.0       11.0        4.0          4         11         11   \n",
      "\n",
      "       able4Hov2  able4Hov3  \n",
      "0              3          3  \n",
      "1              6          6  \n",
      "2              3          3  \n",
      "3              6          6  \n",
      "4              6          6  \n",
      "...          ...        ...  \n",
      "39509         11         11  \n",
      "39510         11         11  \n",
      "39511         11         11  \n",
      "39512          8          8  \n",
      "39513         11         11  \n",
      "\n",
      "[39514 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inspect the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Convert date columns to datetime with specified format\n",
    "df['startDay'] = pd.to_datetime(df['startDay'], format='%d-%m-%Y', errors='coerce')\n",
    "df['endDay'] = pd.to_datetime(df['endDay'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "# Check for invalid dates\n",
    "print(\"Invalid startDay entries:\")\n",
    "print(df[df['startDay'].isna()])\n",
    "\n",
    "print(\"Invalid endDay entries:\")\n",
    "print(df[df['endDay'].isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef15d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12080\\3888300783.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['start'] = pd.to_datetime(df['startDay'].astype(str) + ' ' + df['startTime'].astype(str), errors='coerce')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12080\\3888300783.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['end'] = pd.to_datetime(df['endDay'].astype(str) + ' ' + df['endTime'].astype(str), errors='coerce')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Columns 'id' and/or 'id_2' are not found in the DataFrame.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 51\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv('dataset-1.csv')\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m incorrect_timestamps \u001b[38;5;241m=\u001b[39m time_check(df)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(incorrect_timestamps)\n",
      "Cell \u001b[1;32mIn[43], line 26\u001b[0m, in \u001b[0;36mtime_check\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     24\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mï»¿id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and/or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are not found in the DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Function to check completeness for each group\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_group\u001b[39m(group):\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Columns 'id' and/or 'id_2' are not found in the DataFrame.\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def time_check(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Use shared dataset-1 to verify the completeness of the data by checking whether the timestamps \n",
    "    for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing columns 'id', 'id_2', 'startDay', 'startTime', \n",
    "                               'endDay', and 'endTime'.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Boolean series indicating whether each (id, id_2) pair has incorrect timestamps.\n",
    "    \"\"\"\n",
    "    # Strip leading/trailing spaces from column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Combine date and time for start and end timestamps\n",
    "    df['start'] = pd.to_datetime(df['startDay'].astype(str) + ' ' + df['startTime'].astype(str), errors='coerce')\n",
    "    df['end'] = pd.to_datetime(df['endDay'].astype(str) + ' ' + df['endTime'].astype(str), errors='coerce')\n",
    "\n",
    "    # Create a MultiIndex DataFrame grouped by (id, id_2)\n",
    "    if 'id' in df.columns and 'id_2' in df.columns:\n",
    "        grouped = df.groupby(['id', 'id_2'])\n",
    "    else:\n",
    "        raise KeyError(\"Columns 'id' and/or 'id_2' are not found in the DataFrame.\")\n",
    "\n",
    "    # Function to check completeness for each group\n",
    "    def check_group(group):\n",
    "        days_covered = set()\n",
    "        for _, row in group.iterrows():\n",
    "            day_start = row['start'].floor('D')\n",
    "            day_end = row['end'].floor('D')\n",
    "            days_covered.update(pd.date_range(day_start, day_end, freq='D').date)\n",
    "        \n",
    "        full_week = {0, 1, 2, 3, 4, 5, 6}  # Representing days of the week\n",
    "        days_of_week = {pd.Timestamp(day).dayofweek for day in days_covered}\n",
    "\n",
    "        return not days_of_week.issuperset(full_week)\n",
    "\n",
    "    result = grouped.apply(check_group)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('dataset-1.csv')\n",
    "incorrect_timestamps = time_check(df)\n",
    "print(incorrect_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bcf3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
